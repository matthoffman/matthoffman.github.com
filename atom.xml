<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[matt thinks so]]></title>
  <link href="http://matthoffman.github.com/atom.xml" rel="self"/>
  <link href="http://matthoffman.github.com/"/>
  <updated>2012-10-08T03:50:09-04:00</updated>
  <id>http://matthoffman.github.com/</id>
  <author>
    <name><![CDATA[Matt Hoffman]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[In Defense of Easy]]></title>
    <link href="http://matthoffman.github.com/blog/2012/10/06/complexity/"/>
    <updated>2012-10-06T00:00:00-04:00</updated>
    <id>http://matthoffman.github.com/blog/2012/10/06/complexity</id>
    <content type="html"><![CDATA[<h2 id="the-setup">the setup</h2>

<p>I watched Rich Hickey’s talk from Strange Loop called <a href="http://www.infoq.com/presentations/Simple-Made-Easy">“Simple Made Easy”</a>, which has been making the rounds recently<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. He’s a great speaker, and always makes interesting points. But something in that talk didn’t sit right with me<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>. While his slide about Development Speed (“emphasizing ease gives early speed…ignoring complexity will slow you down over the long haul”) really struck a chord<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>, it felt like he was shortchanging “easy” in favor of “simple”<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>.  This, then, is my long, somewhat circuitous exposition on that thought.</p>

<h2 id="the-case-study">the case study</h2>

<p>I’m working on software that I’ve been involved with for several years. Like a lot of projects, its evolved as the company’s (and their clients’) needs have changed, and it’s been written under schedule pressures and ever-shifting requirements – in other words, it’s like most software, as far as I can tell. I dream some days of VC-funded startups in their Herman Miller chairs building beautiful software from scratch with plenty of cash and plenty of time, but I suspect the grass isn’t really so green over there. </p>

<p>The application has gotten to the age where the layers of rapid development are starting to take their toll: new developers coming onto the project complain that the software is just too complex. By ‘complex’, they mean, “it’s hard to wrap my brain around all of the moving parts.” Some of the symptoms of this version of ‘complexity’ include: </p>

<ul>
  <li>it takes a very long time to get new developers up to speed</li>
  <li>there are a fair amount of bugs caused by changes made to one part of the application which had downstream impacts on other parts of the application. Since most developers don’t have the “big picture” in mind, they don’t know they’re breaking things when they make changes.</li>
  <li>writing new features takes a long time, since the developer needs to know a lot, juggle a lot, and dodge all kinds of pitfalls in order to put something new in place.</li>
</ul>

<p>When I interviewed developers about where the problems were, I got answers like this: </p>

<ul>
  <li>You have to keep too many things in mind at any one time. </li>
  <li>what different parts of the application are doing, upstream and downstream of the piece you’re looking at right now – how all the pieces fit together.</li>
  <li>details of the domain: you have to have some familiarity of what the end goal is in order to understand what things are doing.</li>
  <li>terminology: there’s a lot of terminology that is domain-specific, but it also isn’t entirely consistent throughout the application.</li>
  <li>the pattern at work in the part of the application you’re looking at: different parts of the application follow different general patterns to do what they do.</li>
  <li>the version of the code you’re looking at:  since there are several clients using different versions of the application, some several years old, even if you’ve gotten your head around a section of code in one codebase, there is no guarantee that the accomplishment will translate to another client.</li>
</ul>

<p>But, is simplicity the root issue? How do we fix it? And how would we prevent it in the first place?</p>

<h2 id="theoretical-aside">theoretical aside</h2>

<p>Here’s my limited understanding of educational psychology:<br />
We’re built to only handle a small number of things in working memory (7 things, on average – like a phone number<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>). To understand more complicated things, we have to either “swap out” to longer-term memory or synthesize several related things into one well-understood thing. </p>

<p>Swapping out takes a long time, and is tiring…how many of us have been reading through technical documentation and gotten to a point where we said, “Oh, wait… the author explained what that term meant, or what that component did…what was it again?”  That’s the effect of running out of working memory and having to look in long-term memory to find something you recently read. But more often than not, that factoid probably hadn’t been committed to long-term memory yet, so we had to go back and re-read part of the document.
Synthesizing is the process whereby you understand a group of related things as a whole, so that you’re able to think of the whole as one unit, rather than the component parts. This takes time: you have to “wear grooves” in your brain in an identifiable pattern. For example, when we see a face, we don’t see individual facial features – ears, a nose, a mouth, and eyes – and then try to juggle all of these features to understand whose face it is. We recognize a face as an identifiable whole. Through many repeated exposures, our brains have synthesized that pattern as “a face”, and deal with it as a single item in our memory. That’s also why elementary school teachers drill math facts – if you have internalized that 8 x 7 = 56, you don’t need to store 8 and 7 in working memory and perform the arithmetic…“8x7=56” is a discrete whole in your brain.</p>

<p>For folks learning a new piece of software, especially a large software system, there’s a lot of individual pieces that have not yet been synthesized into understandable, well-understood wholes. And for many large software systems – mine included – getting to that point of familiarity with is more difficult than it needs to be. </p>

<h2 id="definitions">definitions</h2>

<p>Now that I’ve butchered psychology and complexity science, I’ll move on to butcher Rich Hickey’s talk. 
In case you haven’t watched it, here’s the rough paraphrase of the definitions that he bases his thesis around:<br />
* “complex” means combining two or more things (“complecting”). 
* “simple” means “concerned with only one thing”. 
* “easy” means “lie near” or “close at hand”.  Relative to the speaker. 
* Conversely, “hard” means “(conceptually) distant”.</p>

<p>I think it’s fair to say that Rich felt simplicity is the important metric, while “ease” is superficial. </p>

<p>Meanwhile, it’s worth noting that <a href="http://www.merriam-webster.com/dictionary/complex">Merriam-Webster’s definition of “complex”</a> is, in part: </p>

<blockquote>
  <p>1: a whole made up of complicated or interrelated parts <a complex="" of="" welfare="" programs=""> <the military-industrial="" complex="">
2c : a group of obviously related units of which the degree and nature of the relationship is imperfectly known</the></a></p>
</blockquote>

<p>(some unrelated definitions omitted)</p>

<h2 id="complex-or-hard">complex or hard?</h2>

<p>Here’s where things get dicey. It seems clear that making things simpler, in Rich Hickey’s sense, would be a real benefit. In this particular application, there are a lot of places that are combining “what to do” and “how to do it”. There are optimizations that have led to I/O-related code mixed into business logic, for example. And the level of abstraction is generally too high; our business logic has to concern itself with a lot of plumbing around “when” and “where”, instead of focusing on “what”. If each component focused only on the “what” of one portion of the business logic, it would certainly be easier to understand. </p>

<p>But it also seems clear that many of the developers’ complaints – “we can’t keep it all in our heads at once”, “we don’t understand how the pieces fit together”, and so on – aren’t really about “complexity” in Rich Hickey’s sense. They are in Merriam-Webster’s sense: “a group of obviously related units of which the degree and nature of the relationship is <em>*imperfectly known*</em>”. But by Rich Hickey’s definition, being hard to conceptualize is “hard”, not “complex”. </p>

<p>Perhaps there’s a broader way that the “single purpose” definition of simplicity could be applied to the application as a whole that I haven’t thought of. But at the micro level, lots of very distinct pieces with a single concern don’t necessarily make it easier to understand the big picture. In some cases, his suggestions may make that worse: a rules engine, for example. </p>

<p>Having important information (“should we follow path X or Y?”) abstracted out to a rules engine is, in Hickey’s terms, <em>hard</em>: it makes important parts of the application no longer near the code itself.  So the code determines what, the rules engine determines why (or is it when? not sure) by, i assume, composing the “whats” into a control flow.  And then when you’re trying to debug something, you have to go back and forth between the two.  That’s simple, in that the two are separated. But the conceptual “surfaec area”, if you will, is much larger. You have to hold a lot in your head to understand the behavior of the application.</p>

<p>Perhaps generally, simplicity in this “single-purpose” sense help greatly when understanding the individual component, but make understanding the application as a whole <em>harder</em> (using, again, Rich Hickey’s definition of <em>hard</em>). But <em>easy</em> and <em>hard</em> don’t matter, right? They’re relative to the particular developer, they’re a matter of convenience…right? </p>

<p>Perhaps I am reading more into that dichotomy than I should. Casting things in black and white is a perfectly reasonable rhetorical device – especially in a fairly short talk – and that’s what Rich Hickey has done here. Exploring all of the subtleties distracts from the thrust of the talk, and simply doesn’t fit into that format. But I just want to explore what those subtleties are. Because in the case we’re looking at here, “easy” matters if it’s making things hard enough to understand that you have to work on the application for years before understanding enough to add new features. And they certainly matter when there’s only a couple developers who can get paged at 3 AM when things go wrong. </p>

<p>There are real advantages of “easy”, where “easy” is defined as “near to our understanding/skill set”. Less conceptual weight means more working memory can be applied to the problem at hand. Less conceptual weight means less effort expended on the tool itself, more effort to expend on the problem at hand. That is inherently pleasant for engineers – it is very frustrating to put a lot of effort into the tool instead of the problem.  On the flip side, once a tool is mastered, it is very, very pleasant to be able to whip through a problem efficiently: see Vi vs. Notepad.</p>

<p>The argument is similar to the argument that Scala proponents make<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>: eventually, the concepts that are currently very conceptually weighty (<em>so</em> many things to keep in mind!) will eventually be internalized and synthesized, and then it is better, because you can attack your problems better. The question is, is the frustration of the synthesis time (the “learning curve”) worth it?</p>

<p>So perhaps my argument is one of degree. When understanding the application becomes hard enough that the ramp-up time for new developers becomes untenable for the developers themselves – not just the managers that want an easily-interchangable workforce – then steps need to be taken to make things <em>easier</em>. </p>

<h2 id="fix-it-fix-it">fix it! fix it!</h2>

<p>So, if hard matters, what can we do about it?   </p>

<p>In this particular case study, there are several things that would help, and everyone reading this far has thought of several more. In fact, I’d be willing to bet that everyone reading said, “Well, clearly, what you should be doing is —-“, where each reader will fill in that blank a different way. That’s because the world of Software Engineering has come up with all kinds of ways to make large systems easier to deal with. Here’s a few: </p>

<h3 id="visualizing-the-abstractions">visualizing the abstractions</h3>

<p>Visualizing the various related portions together saves you from having to hold parts in memory as you look at other parts – it’s all available right in front of you. Seeing how things work together also helps you synthesize them into a whole. To get a clear picture by looking at the code, you have to have internalized what each of the components do and how they connect. And since there’s far more than 7 components in those networks, they don’t all fit in working memory. So until you’ve internalized and synthesized the components and how they interact, it just feels overwhelming. </p>

<p>Visualizing the flow of data through the system is a similar problem. We have sequences of jobs that read various values from the database and then insert or update other values.  There’s no way to visualize at a high level what components set data and what components are reading that data. </p>

<p>When reading through the code, I’m essentially trying to construct a mental picture of how it’s all fitting together. Add in any abstraction layer, like a dependency injection framework, and things get even harder: “what components do” and “how the components fit together” are defined in two different places (Java files and Spring context xml files, for example, for the Spring framework). If I could somehow visualize it all on one screen, it would save me the effort of constructing a mental picture… ideally I would be able to see both what components do (popup or mouseover descriptions?) and how they fit together. That would be a lot less to juggle in working memory.</p>

<h3 id="contracts">contracts</h3>

<p>In cases where the pieces of the application need to fit together but developers aren’t likely to hold all of those pieces in memory, defined contracts are an age-old solution. The theory is, you don’t <em>have</em> to hold it all in memory; just the compoent you’re working on, up to and including the contracts it has with neighboring components. How they fulfill their contracts is outside your concern. </p>

<p>Whatever form those contracts take, you need to be able to explicitly specify (in an automatically-verified way) what each component expects from others.</p>

<p>In the software in question, there <em>are</em> contracts in place between components…why those aren’t making things simpler for developers is a subject for another blog post.</p>

<h3 id="consistency">consistency</h3>

<p>If everything followed the same pattern, there you would only have to learn that pattern once. Then hopefully, like a face, every new job you saw would just look like a different but recognizable instance of the same pattern. </p>

<p>Consistency also helps in tooling – if everything fits the same pattern, you could create visualizations that worked for every use. </p>

<p>Of course, you can only be as consistent as your actual patterns of use. In this case study, there’s not yet a single pattern that meets the needs of all parts of the system. Some are iterating over data elements and performing relatively simple calculations on each, while others are constructing huge in-memory graphs of time-phased data and using those for some rather complicated calculations. With some more thought, though… </p>

<p>Another form of consistency is a universal vocabulary: if everything used the same term for the same concept, you’d only have to learn the definition once. Terminology was specifically called out as a barrier to understanding. <a href="http://en.wikipedia.org/wiki/Domain-driven_design">“Domain-Driven Design”</a> practitioners stress a consistent “ubiquitous language” for this reason. Honestly, I’m not sure how big of an issue this ends up being; it is a huge early barrier for new hires, but one that fades pretty quickly.</p>

<h3 id="comprehensive-integration-test-coverage">comprehensive integration test coverage</h3>

<p>This doesn’t really help in understanding the system, but does give developers some level of confidence that, while they don’t understand the whole system, they’ll know if their change has broken it. Depending on the tests, they can potentially serve as a form of documentation. And of course it has other benefits as well – like, having components that are tested. </p>

<p>And of course, the classic </p>

<h3 id="documentation">documentation</h3>
<p>As a last resort, documenting preconditions and postconditions, defining terms, explaining patterns and paradigms in static documentation can help.</p>

<p>Documentation is a distant last place. At best it can help you internalize some piece of the application, but in practice it will just presenting data that you then have to hold in working memory while you try to reason about the system. You as the reader then have to go through the effort of reading and reviewing it in order to try to commit it into long-term memory. The more complicated the component or concept is, the less useful documentation is.  </p>

<p>Documentation is also out-of-date as soon as it is written, it’s never maintained, has to be discoverable for the person trying to learn about things, and is high-effort for both the writer and reader. I secretly suspect that, if we could track the number of times that any given page on our internal wiki has been really read, the average across all pages would be &lt; 1. We write more documentation than we read.</p>

<p>There are many, many more. Feel free to tell me your “obviously, you should be doing —!” in the comments. </p>

<h2 id="finally-a-conclusion">finally, a conclusion</h2>

<p>I think Rich Hickey’s division between “simple” and “easy” is useful and instructive…but I think that many of the things that we care about in designing simpler software that falls into what he would call “easy”, rather than “simple”. And if you have a nontrivial number of components, with interactions that will not easily fit within a developer’s working memory until they’ve done a significant amount of synthesis… don’t discount easy. It can save you from that 3AM page. </p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>I started writing this in late 2011, when it was in fact “recently”. It’s now old news, and firmly in the canon of tech talks to watch. Since then, he’s given another wildly popular talk at RailsConf called <a href="http://www.youtube.com/watch?v=rI8tNMsozo0">“Simplicity Matters”</a>.  I won’t be referencing it here, but it’s worth your time as well.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>I’m well aware that, when I disagree with Rich Hickey, the chances of me being right aren’t very good. <a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>Yes, a chord. Which, being two or more interwoven notes, is complex. But that’s ok.<a href="#fnref:3" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>Perhaps someday, I’ll distill it down into a shorter, clearer message. Maybe even a couple dozen powerpoint slides. And maybe then, someone else will point out that the broad brush I used for brevity covered over some other subtlety that they found very important…<a href="#fnref:4" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>The famous <a href="http://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two">“Magical Number 7, Plus or Minus Two”</a><a href="#fnref:5" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p>I like Scala, for the record. <a href="#fnref:6" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cluster Management and Task Distribution: Zookeeper vs. JGroups]]></title>
    <link href="http://matthoffman.github.com/blog/2011/01/29/cluster-management-and-task-distribution-zookeeper-vs-jgroups/"/>
    <updated>2011-01-29T00:00:00-05:00</updated>
    <id>http://matthoffman.github.com/blog/2011/01/29/cluster-management-and-task-distribution-zookeeper-vs-jgroups</id>
    <content type="html"><![CDATA[<div>
<h2 id="internal-source-marker_0.6950423333328217">The question</h2>
Which technology stack makes more sense for a distributed task-management framework?
<h2>The backstory</h2>
The target app I’m working on at the moment is a task-management framework: it distributes discrete units of work (tasks) to workers which may be spread across multiple servers.  Right now, it’s a single-master system: we can add as many nodes as we want (at runtime, if we want) but only one can ever serve as the “master” node, and that node can’t fail.  The master needs to keep track of a bunch of tasks, which have a hierarchical structure (tasks can have one parent and 0-n child tasks).  It manages the tasks&#8217; interdependencies, checks on the health of the worker nodes, and redistributes tasks if they time out or if their worker node goes down.
A lot of task-management systems put tasks in one or more queues (Resque, beanstalkd, etc.); that’s what we did as well, in our first version.  And this works well; you can model a lot of problem domains this way.  But our task data model is a bit more complex than that, though: tasks can have children, and can define whether those children should be executed in serial or in parallel.  So you can define that task A must execute before task B, but then tasks C through Z can execute in parallel.  When Task B executes, it can decide to split its workload up into 100 smaller tasks, B1 through B100, which all execute in parallel, and would all execute before C starts.  So the tasks end up looking more like a tree than a queue&#8230;modeling them as a queue gets a bit convoluted.  You could argue that the best answer would be to re-model our tasks to fit within Resque, beanstalkd, or the like, but at this point that&#8217;d actually be more work. And you can&#8217;t deny this is fun stuff to think about&#8230;

So the single point of failure needs to go.  I’m looking at some of the options for instead distributing the data (the tree of tasks, who&#8217;s executing what, whether the nodes are healthy, whether a task has timed out) across multiple servers.
<h2>The requirements</h2>
<ol>
	<li>Consistency: the task tree should be shared between more than one server, with guaranteed consistency.  I.e if server A is serving as the master node and it goes down, another server needs to be able to pick up and continue, with the exact same view of the current task tree.  We don’t want tasks to accidentally get dropped or executed twice because server B’s version of the task tree wasn&#8217;t up-to-date.</li>
	<li>Elasticity: nodes have to be able to come online and participate in the cluster, and then drop off again.  The full list of nodes can’t be hard-coded at startup.</li>
	<li>Partition-tolerance: Ideally, we should be able to handle a network partition.  We can do that at the expense of availability: that is, if there are 5 nodes, numbered 1 through 5, and nodes 1 and 2 get separated from 3 through 5, it’s OK for 1 and 2 to realize they’re the minority and stop processing.   The following caveats apply:
<ol>
	<li>We need a way to handle an intentional reduction in servers.  That is, if we spun up 10 extra cloud servers for a few hours to help in peak processing, we’d need a way to tell the cluster that we were going to spin them back down again, so the remaining nodes didn’t think they were a minority segment of a partitioned network.</li>
	<li>In case of a catastrophic failure of a majority of servers, I’d like a way to kick the remaining nodes and tell them to process anyway.  But I’m ok if that requires manual intervention&#8230; that’s an extreme case.</li>
</ol>
</li>
	<li>Scalability: I’m targeting 100 nodes as a practical maximum.  In production, we’ve used up to 5 nodes.  I don’t expect us to go above 10 in the near future, so I’m adding an order-of-magnitude safety margin on top of that.  Of course, when the task management framework goes open source, 100 nodes will be quite feasible for users with different problem domains and deployment patterns.  In our typical deployment scenarios, customers prefer fewer, larger servers.</li>
	<li>EC2:  The clustering option has to be able to run on EC2 instances.  It can&#8217;t depend on IP multicast.</li>
	<li>Deployment simplicity:   As few moving parts as possible, to make integrating and deploying the software as simple as possible. Our app is often deployed by the client on their hardware, so we&#8217;d like to make their lives as easy as possible. And as the framework goes open source, of course, it&#8217;s going to be more helpful for a more people if it has a low barrier of entry.</li>
	<li>Implementation simplicity:  The less code I write, the fewer bugs I introduce.</li>
	<li>Event bus:  nodes can also pass events to other nodes, typically by multicast.  We use JMS for this currently, and we can continue to do so, but it’d be nice to get rid of that particular moving part if possible.</li>
</ol>
There is not necessarily a requirement to persist all tasks to disk, in order to keep them safe between server restarts.  In our previous version, tasks were kept in a JMS queue, and we ended up turning disk persistence off &#8211; in practice, in the case of a failure that requires manual intervention (for example, a JMS broker failure, or the failure of all nodes that had tasks in memory) almost always means that we want to manually restart jobs after the system comes back up &#8211; possibly different jobs, possibly a reduced set of tasks to make up time.  We found that we rarely want to start back up exactly where we left off.
So, if the solution automatically persists to disk, I’ll probably create a way to bypass that if necessary (a command-line flag that lets us clear the current tasks on startup, perhaps).
<h2>Zookeeper</h2>
<table><col width="*"></col> <col width="*"></col> 
<tbody>
<tr>
<td>Consistency</td>
<td>Zookeeper pushes everything to disk &#8211; writes are always persisted, for safety.
Zookeeper is designed for cluster coordination, and it’s well-thought-out.  It has documented consistency guarantees, lots of documented recipes for things like leader election, and supports subscription of listeners on tree changes.</td>
</tr>
<tr>
<td>Elasticity</td>
<td>We’d have to pick three servers up front that would serve as Zookeeper nodes as well as normal nodes. Those nodes woulnd’t be elastic, but other nodes could come up and down without a problem.</td>
</tr>
<tr>
<td>Partition-tolerance</td>
<td>The “live” partition would be defined as “the partition that can still connect with the Zookeeper cluster”.   I have to check on how Zookeeper handles network partitions; I believe it’s just a quorum-based algorithm (if one node is separated from the other two, it stops processing).</td>
</tr>
<tr>
<td>Scalability</td>
<td>Three Zookeeper nodes could support 100 nodes without a problem, according to anecdotal experience.  At that point, we would have the option of moving the Zookeeper nodes onto dedicated hardware. Having that option is the upside to Zookeeper’s deployment complexity: you can separate them, if there’s a need.</td>
</tr>
<tr>
<td>EC2-friendliness</td>
<td>Zookeeper uses TCP; it’s been used on EC2 before.</td>
</tr>
<tr>
<td>Deployment Simplicity</td>
<td>The main downside for Zookeeper is its operational requirements:  two classes of servers (with Zookeeper and without), potentially separate server instances running on Zookeeper-enabled servers, fast disk access required (according to the ZK operations manual, two fast disks &#8211; one for logs, the other for … er..something else.)  That’s a significant increase in operational complexity for a product that is distributed to and maintained by clients.  That also means work necessary for us to make it as turnkey as possible.A Zookeeper-based solution would pick three or five nodes to be Zookeeper nodes as well as task nodes.  Ideally, for Zookeeper’s purposes, it’d be three dedicated servers, but that isn’t going to happen in our architecture.  So Zookeeper will have to coexist with the current app on servers where it’s installed.  For deployment simplicity, I’ll probably need to come up with a way to start up Zookeeper automatically when the server comes up on those nodes. Zookeeper used to not play well as an embedded app (according to some reports from the Katta project); that may be fixed now, but if not I may need to put that logic in the bootstrap script.</td>
</tr>
<tr>
<td>Implementation Simplicity</td>
<td>Zookeeper would provide a single, shared view of the task tree.  The system would be up as long as the majority of Zookeeper nodes remained up; any node could be leader, as long as they could connect to Zookeeper to view and update the shared state of tasks.   Other nodes could potentially go straight to Zookeeper to query the task tree, if we were comfortable with losing that layer of abstraction.  Either way, it would be simple implementation-wise.</td>
</tr>
<tr>
<td>Event bus</td>
<td>Zookeeper doesn’t provide events&#8230;unless you write events directly to Zookeeper.  It could, however, obviate the need for a lot of events.  For example, we wouldn’t need a “task finished” event if all nodes just set watches on tasks&#8230;they’d be automatically notified.  Same with hearbeats, node failure, and so on &#8211; they’d be taken care of by Zookeeper.</td>
</tr>
</tbody>
</table>
Zookeeper doesn’t list AIX as a supported environment, which is interesting.  We do have to support AIX (unfortunately).
<h2>JGroups</h2>
<table><col width="*"></col> <col width="*"></col> 
<tbody>
<tr>
<td>Consistency</td>
<td>JGroups is a lot more of a DIY solution, although it supports guaranteed message delivery and cluster management out-of-the-box.
With guaranteed message delivery, we could have consistent in-memory views of the task tree without too much effort; we wouldn’t need to write something that also persisted to disk.</td>
</tr>
<tr>
<td>Elasticity</td>
<td>I have to look into how elastic JGroups can be without IP multicast.  I know it can work without IP multicast; I just don’t know exactly HOW it works.</td>
</tr>
<tr>
<td>Partition-tolerance</td>
<td>Good question&#8230;.</td>
</tr>
<tr>
<td>Scalability</td>
<td>More speculative, because JGroups has the option for infinite combinations of protocols on its stack.  Worst case, the cluster needs to define two classes of nodes, similar to the Zookeeper implementation: “nodes which can become leaders” and “nodes which can’t.”</td>
</tr>
<tr>
<td>EC2-friendliness</td>
<td>JGroups can be used on EC2 as long as you use TCP-based “multicast” instead of actual IP multicast.</td>
</tr>
<tr>
<td>Deployment Simplicity</td>
<td>JGroups would be baked in; worst case, you need to define a couple properties per server (IP of one or more nodes to connect to, and perhaps something like “is this a temporary node”)</td>
</tr>
<tr>
<td>Implementation Simplicity</td>
<td>More DIY.  The basic protocol stack is provided, along with clustering, leader election, “state transfer” (to bootstrap a new node with a current picture of the task tree) and the lower level; we’d just have to tie it together and fill in the gaps for application-specific needs.</td>
</tr>
<tr>
<td>Event bus</td>
<td>JGroups can also give us message passing, taking the place of a simple JMS topic.  I have a lot of questions here, though:  how does this handle nodes dropping?  Does it buffer events until the node comes back on?  If so, how do we handle nodes that permanently drop?</td>
</tr>
</tbody>
</table>
</div>
<h2>Conclusion</h2>
&#8230;tbd&#8230;
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Configuration]]></title>
    <link href="http://matthoffman.github.com/blog/2010/12/10/on-configuration/"/>
    <updated>2010-12-10T00:00:00-05:00</updated>
    <id>http://matthoffman.github.com/blog/2010/12/10/on-configuration</id>
    <content type="html"><![CDATA[I&#8217;ve been musing recently on how to scale our configuration system up and out: making it work more dynamically for single nodes, and handle multiple nodes&#8230;well, at all.
<h2>How it works now</h2>
Right now, our configuration is spread across the following places, roughly in order of precedence:
<ul>
	<li>System properties (-D properties set on the command line)</li>
	<li>a user-editable property file, for overrides to default properties.  This is preserved during system upgrades.</li>
	<li>a &#8220;system defaults&#8221; property file, user-visible but overwritten during upgrades.</li>
	<li>a database table:  for a while, we were standardizing on properties in the database.  More on this later&#8230;</li>
	<li>some property files buried inside jars, which hold some database queries, some default values, and so on.</li>
	<li>log4j.xml</li>
</ul>
We use a MergedPropertyPlaceholderConfigurer, along with a couple other configuration classes available <a title="blast-config on github" href="https://github.com/matthoffman/blast-config">on github</a>) that merges properties from most of the above locations together, ranks them in order of precedence, and then sets them at startup time using Spring&#8217;s standard placeholder syntax (${property.name}). Database properties are loaded from a table using a special Spring property loader.

So any property can be set in a higher-precedence location and it will override one set in a lower-precedence location.

In practice, new properties tend to get set in the property file. Why? Because database changes require a patch (like a migration in the Rails world) which needs to get migrated to each applicable environment.  Deploying the code to a development or test server then requires both a code update and a database update. In practice, the dependency between the code and particular database patches is a bit of a hassle &#8211; certainly far more so than just adding it to a property file which gets deployed along with the code.  A bad motivation for keeping properties in files?  Perhaps&#8230; but it is the reality of it. A system that raises the barrier of entry for doing &#8220;the right thing&#8221; is a bad system.  Which brings us to&#8230;
<h2>Problems with current system</h2>
<ol>
	<li>property files are cumbersome in a distributed environment.  Many of our deployments are single-node, but more and more they&#8217;re distributed, and distributed deployments should be our default going forward.</li>
	<li>For properties stored in the DB, adding, removing or updating any property requires a DB task, and then a DB refresh, which has the effect of discouraging parameterizing things. You tend to think, &#8220;eh, well&#8230; I&#8217;ll just hard-code this for now&#8230;&#8221;</li>
	<li>Properties are loaded at startup time only – you can&#8217;t change property values without changing each property file and then restarting each node.</li>
</ol>
<h2>Requirements for a new system:</h2>
I&#8217;d like to borrow requirements from <a href="http://jim-mcbeath.blogspot.com/2010/01/reload-that-config-file.html">http://jim-mcbeath.blogspot.com/2010/01/reload-that-config-file.html</a>:
<ol>
<li>Reloading a configuration should be a simple operation for the operator to trigger.
<li>It should not be possible to load an invalid configuration. If the operator tries to do so, the application should continue running with the old configuration.
<li>When reloading a configuration, the application should smoothly switch from the old configuration to the new configuration, ensuring that it is always operating with a consistent configuration. More precisely, an operational sequence that requires a consistent set of configuration parameters for the entire sequence should complete its sequence with the same set of configuration parameters as were active when the sequence started. – For us, this is actually pretty easy.  Our app depends on a task distribution framework, meaning that work is defined as a series of tasks with defined beginnings and endings.  So, we merely need to load the configuration at the beginning of each discrete unit of work.
<li>The application should provide feedback so that the operator knows what the application is doing. Logging, notification or statistics about configuration reloads should be available.

<br /><br />&#8230;and I&#8217;d add:
<li>We should be able to set configurations for all nodes at once (this could mean using the database, or perhaps a command-line tool that sprays configurations out to the various nodes, plus a web service to tell nodes to reload..or something else entirely).
<li>We should be able to view the current configuration for each node easily.
<li>We should be able to share configuration between our app and other related applications, again, this could be database, or a web service that exposes our properties to other applications.
</ol>
<h2>Current thoughts</h2>
At the code level, I&#8217;m thinking of loading properties at the beginning of each task, using a base class or something built into the framework.
Reloading and interrogating the configuration could be via a web service (get_configuration / set_configuration). For requirement 3, the easiest option seems to be to use Configgy as a configuration base.
As far as centralized configuration goes, I&#8217;m up in the air. Some options:
<ul>
	<li>Spraying config files (scp&#8217;ing configuration files to each server, which would have to be tied to either an automatic poll of files, or a manual &#8220;reload_configuration&#8221; web service call)</li>
	<li>distributing configuration using a web service (node 2 calls get_all_configuration on node 1, and sets its own configuration accordingly) – but it would need to be saved somewhere in case node 2 restarts when node 1 isn&#8217;t available. The database is an option, but has development-time issues as noted above.</li>
	<li>saving all configuration in Zookeeper.</li>
</ul>
What i&#8217;d really like, though, is a configuration system that kept properties in an immutable data structure that kept track of where properties came from &#8211; so, I could define the locations properties should come from, and then in the application I could say,  &#8220;config.getProperty(&#8216;foo&#8217;)&#8221;  and get the value with the highest precedence (whether that&#8217;s from an override file, a database table, or whatever).  But I could also say &#8220;config.getPropertyDetails(&#8216;foo&#8217;) &#8221; and get a list that said &#8220;property &#8216;foo&#8217; is set to &#8216;bar&#8217; by local override, is set to &#8216;groo&#8217; by the central configuration server, and the &#8216;moo&#8217; as a fallback default.&#8221; Now, why do I want that? Mainly for on-site debugging:  &#8220;I set the property in this property file, but it&#8217;s not working!&#8221;    

<h2>Some related (external) links:</h2>
<ul>
	<li><a href="http://soupinadeli.com/resilient-software-configuration/">http://soupinadeli.com/resilient-software-configuration/</a> - a good article about how a configuration system should work, and why.</li>
	<li><a href="http://jim-mcbeath.blogspot.com/2010/01/reload-that-config-file.html">http://jim-mcbeath.blogspot.com/2010/01/reload-that-config-file.html</a> - another good article, cited above.</li>
        <li><a href="http://stackoverflow.com/questions/1244455/where-how-to-store-distributed-configuration-data">http://stackoverflow.com/questions/1244455/where-how-to-store-distributed-configuration-data</a> - an interesting solution for all-database configuration, with a &#8220;central&#8221; table and a &#8220;local&#8221; table (for &#8220;defaults&#8221; and &#8220;overrides&#8221;, like what I&#8217;m doing currently for property files).   The answerer takes it a couple steps farther, with an interesting SQL analytics query to pull it all in at once. 
        <li><a href="http://commons.apache.org/configuration/">Apache Commons Configuration</a> comes close to the model I described above, with their <a href="http://commons.apache.org/configuration/apidocs/org/apache/commons/configuration/CompositeConfiguration.html">Composite Configuration</a> class.  I looked at Commons Configuration a year or so ago, and thought it was interesting but not quite what I was looking for (and their Hierarchical Configuration concepts can get pretty hairy). But I&#8217;m intrigued by the CompositeConfiguration class, so I need to look into it again.  
Of course, the project is all but dead &#8211; last updated 2008 &#8211; but how often does a configuration library really need to change?  
        <li><a href="https://issues.apache.org/jira/browse/CONFIGURATION-395">Interesting patch</a> to Commons Configuration for Groovy interpolation (i.e. put Groovy in property values, to be evaluated at load-time)
        <li><a href=""></a>&#8230;more to come
</ul>

I&#8217;m open to ideas, as well&#8230;  Anyone have best-practices for distributed configuration?
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Oh, Oracle]]></title>
    <link href="http://matthoffman.github.com/blog/2010/03/05/oh-oracle/"/>
    <updated>2010-03-05T00:00:00-05:00</updated>
    <id>http://matthoffman.github.com/blog/2010/03/05/oh-oracle</id>
    <content type="html"><![CDATA[<p>So, I was responsible for a pretty unfortunate bug today — no way around it, I messed up.  It was classic — there was a &#8220;TODO&#8221; block where I meant to come back and finish some code, and no doubt got distracted by some very valid crisis. </p> 
<p>Fortunately, it was caught before it affected production data, but it was in test, and visible, and it was scary that it had gotten that far.</p>
<p>But I couldn&#8217;t help but be bitter about how that block of code came to be in the first place:  the code that contained the bug was part of an elaborate scheme designed to work around joining to a particularly large table in certain circumstances.</p>
<p>Now, it’s big data (well, at least tens of millions of rows) …we have to do what we can for efficiency.  But it made me slightly bitter that the more we optimize for relational databases, trying to eke more and more performance, the farther we move from a clear data model, and the less we&#8217;re using the &#8220;R&#8221; in RDBMS. We go through contortions, and in the process introduce bugs.</p> 
<p>I’m not sure who that might be a lesson for, but perhaps if anyone is dead-set on using a tried-and-true RDBMS to avoid bugs in newer systems, whether MapReduce or a “NoSQL” store, it’s worth noting that there is some tradeoff here:  bugs in the data store in question vs. bugs you introduce into your own code due to the increased complexity as you contort your data model to make it scale where you need it to go.</p>
 
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[on the cusp of Big Data]]></title>
    <link href="http://matthoffman.github.com/blog/2009/12/19/on-the-cusp-of-big-data/"/>
    <updated>2009-12-19T00:00:00-05:00</updated>
    <id>http://matthoffman.github.com/blog/2009/12/19/on-the-cusp-of-big-data</id>
    <content type="html"><![CDATA[<i>Alternate title:</i> <b>Episode IV: A New Hope</b>

<p>I&#8217;m restarting this blog after a long hiatus &#8211; a couple of years, at least.  It looks like my old posts were purged in the meantime, but that&#8217;s probably for the best<a name="to1" href="#1"><sup>1</sup></a>.  My musings about Hibernate from 2007 are probably not that interesting now<a name="to2" href="#2"><sup>2</sup></a>.</p>
<p>Where I&#8217;m coming from:</p>
<p>I work on a team that, in a lot of ways, is on the cusp of Big Data:  we deal with gigabytes, but not terabytes of data, and we don&#8217;t have endless racks of commodity servers.  We have a homegrown task framework that follows a typical master-worker pattern and allows for tasks to be distributed among nodes on different servers.  That works well, and I like the framework in general &#8211; it could use some cleaning up, but it&#8217;s simple, clean and functional.</p>
<p>Data, though, is all stored inside an Oracle database, and we&#8217;re knocking at the edge of it&#8217;s capabilities.  We haven&#8217;t entirely maxed it out yet, but each performance gain has been harder to come by, and we can easily see the time approaching where it will be cheaper to rearchitect how we&#8217;re storing and serving data rather than eke more performance by smarter partitioning, better queries, or a faster SAN.</p>
<p>So over the past several months I&#8217;ve been reading about some of the competitors in the big-data field, and sketching ideas for what I&#8217;d like our architecture to look like going forward.  Things like MapReduce (Hadoop), HBase, Cassandra, or Terracotta, or a number of other ideas &#8211; different types of products, all with the goal of scaling data beyond a single server.  But unlike a lot of folks looking at these options, we have an existing product in production, based on a framework that does 80% of what we need.  So I find myself on a seesaw, going between the newest, coolest thing I&#8217;ve read about, and then the pain of rewriting what we have on a non-existent timeline when what we have works so well &#8211; at today&#8217;s data volumes.</p>
<p>I decided to reinstate this blog to collect what I&#8217;ve learned so far.</p>
<p/>
<p/>
<p><a name="1" href="#to1"><sup>1</sup></a> Does anyone else have the problem of starting blogs like new years&#8217; resolutions and then losing track of them?  I probably have three out there, tied to some forgotten username on goodness knows which host, and they&#8217;re probably saying very insightful things about Hibernate 2.0.</p>
<p><a name="2" href="#to2"><sup>2</sup></a> Turns out, I did recover some old posts from a Typo blog from 2006.  A couple of the most boring just didn&#8217;t make the move over, but most of them are here for morbid curiosity about what seemed interesting at the time.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSL curiosity]]></title>
    <link href="http://matthoffman.github.com/blog/2006/09/13/ssl-curiosity/"/>
    <updated>2006-09-13T00:00:00-04:00</updated>
    <id>http://matthoffman.github.com/blog/2006/09/13/ssl-curiosity</id>
    <content type="html"><![CDATA[<p>Ok, perhaps this isn’t a curiosity to you all.  Perhaps everyone knew this.  But I didn’t, and I didn’t find it in a quick Google search, so I thought I’d put it out here.    </p>

<p>I’m working on a project that uses 2-way (client-auth) SSL; in doing so, I’ve created a test root CA and used it to generate an array of test certs for clients and servers. I’ve done a bit of testing on my local PC, and it’s working well; the server uses client certificates for authentication and authorization of web service requests, and so on. Acegi is our friend. </p>

<p>However, another developer on the project tried accessing the site not long ago and told me it didn’t work.  “I just get ‘Cannot find server’”, he said.  Turns out that he was using Internet Explorer, and I had been using Firefox. I could replicate his results with IE – the browser would give the prompt saying “This site’s certificate is not trusted” or something to that extent, and then when you said “accept the certificate”, it would throw up a “Cannot find server” error.  The same series of steps in Firefox would work without a problem.    </p>

<p>After fiddling a bit, it turns out that adding the test CA to my Trusted Root Certificate Authorities list fixed the problem.  Honestly, I’m not sure why this would be necessary, if Internet Explorer had already asked me whether to accept the site’s certificate, but my best guess is that IE was simply ignoring my answer and refusing to load the site whose certificate was signed with an unknown root CA.   </p>

<p>Again, maybe this is a known bug, but hey, I thought I’d throw it out there.  Adding the test CA to IE’s “trusted root certificates” list fixed the problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Another library]]></title>
    <link href="http://matthoffman.github.com/blog/2006/06/16/jamon/"/>
    <updated>2006-06-16T00:00:00-04:00</updated>
    <id>http://matthoffman.github.com/blog/2006/06/16/jamon</id>
    <content type="html"><![CDATA[<p>I’ve been teased that my current project has more external libraries than it does actual lines of code.  Now, I’m not convinced that’s a bad thing – I’ve said before that the hardest thing about leaving Java for some other language would be giving up all of the 3rd-party libraries and projects that do 90% of your work for you. </p>

<p>Today’s is JAMon, a small library with a really simple purpose: keep track of performance statistics. I’ve written static classes or singletons that keep track of min, max and average times for various things on several projects; this just keeps me from having to write it again. Not saving a ton of time, but saving some. And <a href="http://iremia.univ-reunion.fr/intranet/wiki/Wiki.jsp?page=SpringJamon">here</a> is a simple step-by-step for integrating it into Spring as an interceptor. There are several discussions out there for how to use JAMon with Spring, and whether Spring’s built-in JAMon interceptor (is there anything Spring <em>doesn’t</em> have built in?) should use logging semantics to activate it, but the one above is simply the XML to cut and paste into Appfuse’s Spring config, which is all I really want. I understand what it does, it’s just saving me the five minutes of thinking about it.  Which is what I’m after.  It’s just a beautiful feeling when you want something done, no matter how small, and find that it’s already been done for you.  Like realizing you want another cup of coffee and finding a steaming mug already on your desk.</p>

<p>With that said, I’m going to go make some coffee now… </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Perhaps I'm missing something...]]></title>
    <link href="http://matthoffman.github.com/blog/2006/05/19/axis2/"/>
    <updated>2006-05-19T00:00:00-04:00</updated>
    <id>http://matthoffman.github.com/blog/2006/05/19/axis2</id>
    <content type="html"><![CDATA[<p>I’ve been playing with Axis2 for a couple of days.  One of the features that they boast (and added to XFire’s <a href="http://xfire.codehaus.org/Stack+Comparison">SOAP Stack Comparison</a>) is hot-deployable services. </p>

<p>Has anyone ever wanted to hot-deploy a web service? </p>

<p>Really now…</p>

<p>Granted, I’m sure someone could point out the features in some of my projects that no one really wanted. Or, perhaps, someone should point out why in fact this is a killer feature and I’ve just missed it. But it seems particularly weird to me…</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[For the record...]]></title>
    <link href="http://matthoffman.github.com/blog/2006/05/16/for-the-record/"/>
    <updated>2006-05-16T00:00:00-04:00</updated>
    <id>http://matthoffman.github.com/blog/2006/05/16/for-the-record</id>
    <content type="html"><![CDATA[<p>For the record, a custom STaX serializer and deserializer for a moderately small object graph will run you about 1000 lines of code. </p>

<p>Just in case you were curious. </p>

<p><i>update, 2006-08-23: </i></p>

<p>Correction: it’s now up to 2000.  It also supports another (rather different) schema that is being mapped to the same domain object, which accounts for much of the increase.</p>

<p>Just thought you might be interested. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Love-Hate of JiBX]]></title>
    <link href="http://matthoffman.github.com/blog/2006/05/01/the-love-hate-of-jibx/"/>
    <updated>2006-05-01T00:00:00-04:00</updated>
    <id>http://matthoffman.github.com/blog/2006/05/01/the-love-hate-of-jibx</id>
    <content type="html"><![CDATA[<p>Ok, I love JiBX’s flexibility.  I have two different versions of an existing schema that I’m mapping to the same Java object, which is the same Java object I’m then storing in Hibernate.  This is the first time I’ve been able to use the same domain object throughout the application, and I love it.  No more relying on framework-generated objects, and no more translation layers.</p>

<p>Framework-generated objects are bad for my schemas, which have a lot of nested anonymous complex types (hey, I didn’t write them) which frameworks tend to handle badly.  XMLBeans, for instance, creates nested inner types, which gets very ugly.  It may be personal preference, but that seems very messy; it means one very large object. Hibernate, I imagine, would also be unhappy with that setup. </p>

<p>So the alternative is a translation layer – a class that takes in a WebserviceFriendlyDomainObject and spits back a HibernateFriendlyDomainObject. This is a pain to write, but mostly just smells bad – it just shouldn’t be necessary.  I’ve done it as a workaround so far, but it seems like there should be a way around it.</p>

<p>JiBX lets me use the same object from front to back. But that brings me to one of the hates – I have to write a JiBX binding file instead.  It’s funny, because for whatever reason this passes under the “ugly architecture” radar, but it’s actually not much different than writing a translation layer. It’s just writing your translation layer in XML instead of in Java. Which, if anything, simply adds difficulty, because I find myself trying to do complex logic in the binding file that could really benefit from a Turing-complete language. Which is ironic, since I’m writing it to save me from writing the same thing in Java. </p>

<p>Now, it’s still a bit better than a translation layer. The typical translator is converting one object to another object to be turned into XML. The JiBX binding is going straight to XML. It’s certainly faster than the translation step. But from the coder’s point of view, the XMLBeans-generated domain object is one method call away from being XML, so it doesn’t <i>feel</i> substantially different.</p>

<p>My other complaint about JiBX so far is web service support – it’s pretty new, and support in Axis2 (another topic entirely) and XFire is either brand-new or still in CVS.  I’m finding that my data binding layer is informing my choice in web service stacks, which I resent.  I haven’t tried XFire’s JiBX support yet (since Codehaus’s SVN server is down) but they were planning on getting it into 1.1 and it didn’t make it, which isn’t a good sign. </p>

<p>The annoyances of bytecode manipulation are already documented elsewhere; I’ve found that every now and again I have to run an ant task that inserts the JiBX bindings into Eclipse’s class files, and that’s the extent of it. It irks some of people, but doesn’t bother me. </p>

<p>So I’m not sure if JiBX will stay around in this project. That’s in spite of substantial positives – at this point, it could easily fall either way. </p>

<p><i>Update, 2006-05-16:</i></p>

<p>It didn’t stay around. In the end, expressing logic (“if this element… else if this element…”) in XML was too much. I moved over to a hand-rolled STaX serializer and deserializer – see <a href="http://matthoffman.github.com/2006/05/16/for-the-record.html">“for the record”</a> for a quick peek into the main downside there. </p>

<p>Why I went this route instead of XMLBeans or JAXB merits more discussion.  Briefly, JAXB didn’t meet the performance requirements for this part of the system, and XMLBeans refuses to fully parse the schemas in question. It tries, but something in the deeply nested anonymous complex types gives it fits.  Writing code against those types as they’re generated in XMLBeans is also ugly, but then so is the custom parser. </p>

<p>All in all, I’m coming to terms with the translation layer. But it still feels like it oughtn’t be necessary…  </p>
]]></content>
  </entry>
  
</feed>
