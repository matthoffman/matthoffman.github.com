--- 
layout: post
title: Oh, Oracle
tags: 
- Big Data
---
So, I was responsible for a pretty unfortunate bug today — no way around it, I messed up.  It was classic — there was a "TODO" block where I meant to come back and finish some code, and no doubt got distracted by some very valid crisis.  Fortunately, it was caught before it affected production data,  but it was in test, and visible, and it was scary that it had gotten that far.

But I couldn't help but be bitter about how that block of code came to be in the first place:  the code that contained the bug was part of an elaborate scheme designed to work around joining to a particularly large table in certain circumstances. 

Now, it’s big data…we have to do what we can for efficiency.  But it made me slightly bitter that the more we optimize ofr relational databases, trying to eke more and more performance out of Oracle, the farther we move from a clear data model, and the less “relational” we’re using our RDBMS for.   We go through contortions, and these introduce bugs. 

I’m not sure who that might be a lesson for, but perhaps if anyone is wondering the tradeoffs of  using a tried-and-true RDBMS to avoid bugs in newer systems, whether MapReduce or a “NoSQL” store, perhaps it’s worth noting that there is some tradeoff of bugs in the data store in question vs. bugs due to the increased complexity of your own code introduced as you contort your data model for performance’s sake. 
 
